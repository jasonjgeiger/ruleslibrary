---
description: 
globs: 
alwaysApply: false
---
# Responsible AI Implementation Rules

*Based on Microsoft HAX Toolkit - Complete Pattern Catalog*

## Core Principle
Proactively implement responsible AI practices using Microsoft's 18 HAX Guidelines, educate users about best practices, prevent misleading AI experiences, and communicate severity through clear visual indicators.

## Auto-Attachment Scope
This rule automatically applies to:
- **AI/ML Code**: Python ML/AI libraries, Jupyter notebooks, R scripts, AI model files
- **Frontend Components**: React, Vue, Svelte, Angular components with AI features
- **Backend Services**: API endpoints, microservices, serverless functions handling AI
- **Mobile Apps**: iOS (Swift), Android (Kotlin/Java), React Native, Flutter with AI features
- **Web Applications**: Full-stack applications with AI integration
- **Configuration Files**: AI model configs, deployment configs, environment settings
- **Documentation**: Technical docs, API docs, user guides for AI features
- **Data Processing**: ETL scripts, data pipelines, preprocessing code
- **Infrastructure**: Docker, Kubernetes, cloud deployment files for AI services
- **Testing Files**: Unit tests, integration tests, AI model validation scripts

## Rule 1: Proactive UI Pattern Implementation

### 1.1 Automatic Pattern Integration
When creating any UI component that involves AI interaction, automatically include:

**For System Capability Communication (G1)**:
```
✨ AUTO-IMPLEMENTED: Capability Communication
Pattern 1A: Introductory blurb added
Location: [component/feature description]
Content: "This AI can [specific capabilities] but cannot [limitations]"
```

**For Performance Transparency (G2)**:
```
🎯 AUTO-IMPLEMENTED: Confidence Indicators
Pattern 2A: Language precision matching
- Use "might", "likely", "uncertain" based on confidence
- Pattern 2D: Low performance alerts when confidence < 70%
```

**For User Control (G7, G8, G9, G17)**:
```
🔧 AUTO-IMPLEMENTED: User Controls
- Easy invocation mechanism (G7)
- Quick dismissal option (G8) 
- Correction interface (G9)
- Settings/preferences access (G17)
```

**For Explanation Access (G11)**:
```
💡 AUTO-IMPLEMENTED: Explanation Interface
- "Why this result?" button/link
- Pattern 11A: Local explanations for decisions
- Pattern 11F: Example-based explanations when complex
```

### 1.2 Contextual Safety Controls
Automatically include safety mechanisms:

**For Uncertainty Handling (G10)**:
```
🛡️ AUTO-IMPLEMENTED: Safety Controls
Pattern 10A: Disambiguation prompts when uncertain
Pattern 10C: Fallback strategies clearly indicated
```

**For Change Management (G18)**:
```
📢 AUTO-IMPLEMENTED: Change Notifications
- Version/behavior change indicators
- "What's new" or "Recent changes" section
```

### 1.3 File Type Specific RAI Implementation

**Frontend Components (.jsx, .tsx, .vue, .svelte)**:
- Auto-add capability descriptions in component props/documentation
- Include confidence indicators for AI-generated content
- Implement user control buttons (edit, dismiss, explain)
- Add loading states with uncertainty messaging

**Backend APIs (.py, .js, .ts, .java, .go, etc.)**:
- Include confidence scores in API responses
- Add explanation endpoints for AI decisions
- Implement user feedback collection endpoints
- Add performance monitoring and alerting

**Mobile Components (.swift, .kt, .dart)**:
- Include accessibility labels for AI features
- Add haptic feedback for AI interactions
- Implement offline fallback strategies
- Include user preference persistence

**Jupyter Notebooks (.ipynb)**:
- Add model performance documentation cells
- Include bias testing and fairness analysis
- Document model limitations and appropriate use cases
- Add data source attribution and quality notes

## Rule 2: User Education and Recommendations

### 2.1 Pattern-Based UI Improvement Education

When reviewing existing UI or suggesting improvements, educate the user:

**Format for Recommendations**:
```
📚 RAI EDUCATION: [Pattern Name]
Guideline: [G# - Description]
Current State: [what exists now]
Recommendation: [specific improvement]
Complexity: [Low|Medium|High]
Implementation: [if Low] Auto-implementable
               [if Medium/High] Recommended for manual implementation
Example: [concrete example]
User Benefit: [why this helps users]
```

### 2.2 Complex Pattern Guidance

For complex implementations, provide educational guidance instead of auto-implementation:

**High-Complexity Patterns Requiring Manual Implementation**:

**Pattern 15A-15D (Granular Feedback)**:
```
🎓 EDUCATION NEEDED: Feedback Collection System
⚠️ Complexity: HIGH - Manual implementation recommended

Recommendation: Consider implementing feedback collection
- Pattern 15A: Individual output ratings (👍/👎)
- Pattern 15B: Strategic sampling (not every output)
- Pattern 15C: Inappropriate content reporting mechanism
- Pattern 15D: Implicit feedback tracking (optional)

Implementation Guidance:
1. Start with simple thumbs up/down (Pattern 15A)
2. Add reporting mechanism for safety (Pattern 15C)
3. Consider usage analytics as implicit feedback (Pattern 15D)
4. Avoid feedback fatigue - use Pattern 15B sampling

DON'T AUTO-CREATE: Backend services, analytics systems, or databases
DO RECOMMEND: UI placement, interaction patterns, user flow design
```

**Pattern 13 (Learn from user behavior)**:
```
🎓 EDUCATION NEEDED: Behavioral Learning System
⚠️ Complexity: HIGH - Manual implementation recommended

Recommendation: Consider implementing user behavior learning
- User preference tracking
- Interaction pattern recognition
- Personalization based on usage

Implementation Guidance:
1. Start with explicit preference settings
2. Consider privacy-preserving analytics
3. Implement gradual personalization (Pattern 14B)
4. Always provide user control (Pattern 17)

DON'T AUTO-CREATE: Machine learning systems, user tracking, or data storage
DO RECOMMEND: Preference UI, personalization options, transparency controls
```

### 2.3 Progressive Enhancement Recommendations

Suggest implementation phases for complex patterns:

```
🚀 IMPLEMENTATION ROADMAP: [Feature Name]
Phase 1 (Immediate): [Low complexity patterns]
Phase 2 (Short term): [Medium complexity patterns]  
Phase 3 (Long term): [High complexity patterns]
User Control Priority: [Always implement first]
Safety Priority: [Critical safety patterns]
```

## Rule 3: Misleading AI Experience Prevention

### 3.1 Misleading Practice Detection

When detecting potentially misleading AI implementations:

**Detection Triggers**:
- Over-inflated capability claims (violates G1, G2)
- Hidden AI involvement (violates G1)
- No uncertainty communication (violates G2)
- No user control options (violates G7, G8, G9, G17)
- No explanation access (violates G11)
- Biased or unfair representations (violates G6)

**Alert Format**:
```
🚨 MISLEADING AI PRACTICE DETECTED 🚨
Violation: [Specific misleading practice]
Guidelines Violated: [G# with descriptions]
Evidence: [Why this is misleading]
User Harm: [Potential negative impact]
Resolution Required: [Specific fixes needed]

RESOLUTION RECOMMENDATIONS:
1. [Immediate fix] - [G# pattern reference]
2. [Structural change] - [G# pattern reference]  
3. [Long-term improvement] - [G# pattern reference]
```

### 3.2 Specific Misleading Practice Alerts

**Over-Capability Claims (G1/G2 Violations)**:
```
⚠️ MISLEADING CAPABILITY CLAIM DETECTED
Problem: System described as more capable than actual performance
Guidelines Violated: G1 (Make clear what system can do), G2 (Make clear how well)
Evidence: [Specific over-claims identified]
Fix Required: Pattern 1A (Introductory blurb) + Pattern 2A (Language precision)
```

**Hidden AI Usage (G1 Violation)**:
```
🚨 UNDISCLOSED AI USAGE DETECTED
Problem: AI involvement not transparent to users
Guideline Violated: G1 (Make clear what the system can do)
Ethical Issue: Violates user's right to know they're interacting with AI
Fix Required: Pattern 1A (Clear AI disclosure) + Pattern 1C (Expose controls)
```

**No User Agency (G7/G8/G9/G17 Violations)**:
```
⚠️ LIMITED USER CONTROL DETECTED
Problem: Users cannot effectively control or correct AI behavior
Guidelines Violated: G7 (Invocation), G8 (Dismissal), G9 (Correction), G17 (Global controls)
Fix Required: Implement user control patterns across all interaction points
```

## Rule 4: Emoji Communication System

### 4.1 Severity Indicators

**Critical Issues (Misleading/Harmful)**:
- 🚨 Critical RAI violation requiring immediate attention
- ⚠️ Significant concern needing resolution
- 🛡️ Safety mechanism missing or inadequate

**Implementation Status**:
- ✅ RAI best practice successfully implemented
- 🎯 Good practice with room for improvement  
- 📚 Educational opportunity identified
- 🚀 Enhancement recommendation provided

**Pattern Categories**:
- 🤖 System capability and transparency (G1, G2, G11)
- 🎛️ User control and efficiency (G7, G8, G9, G17)
- 🧠 Learning and adaptation (G12, G13, G14)
- 💬 Feedback and consequences (G15, G16)
- 🛡️ Safety and caution (G10, G18)
- 🌍 Social responsibility (G5, G6)
- ⚡ Context awareness (G3, G4)

### 4.2 Positive Reinforcement

When good RAI practices are implemented:

```
✨ EXCELLENT RAI IMPLEMENTATION! ✨
Pattern Implemented: [Pattern name and number]
Guidelines Followed: [G# list]
User Benefit: [Specific benefit provided]
Best Practice Highlight: [What makes this exemplary]

🎉 Additional Patterns to Consider:
- [Related pattern suggestions]
- [Enhancement opportunities]
```

## Rule 5: Integration with Privacy and Security

### 5.1 Cross-Rule Coordination
Responsible AI rules work in conjunction with privacy-security.mdc:

**Data Protection + Transparency**:
- Pattern 11D (Map inputs to outputs) + Data masking requirements
- Pattern 15D (Implicit feedback) + Privacy controls
- Pattern 13 (Learn from behavior) + Consent mechanisms

**User Control + Security**:
- Pattern 17 (Global controls) + Security settings
- Pattern 9C (Undo actions) + Audit logging
- Pattern 10C (Fallback strategies) + Security fallbacks

### 5.2 Alert Coordination
```
🔒🤖 PRIVACY + RAI COORDINATION
Privacy Rule: [Specific privacy requirement]
RAI Pattern: [Related HAX pattern]
Integrated Solution: [How they work together]
```

## Rule 6: Development Workflow Integration

### 6.1 Pre-Implementation Checklist

Before implementing any AI feature:
```
📋 RAI PRE-IMPLEMENTATION CHECKLIST
🤖 G1: Capability communication planned? (Pattern 1A-1E)
🎯 G2: Performance transparency included? (Pattern 2A-2D)  
🛡️ G10: Uncertainty handling designed? (Pattern 10A-10C)
💡 G11: Explanation mechanism available? (Pattern 11A-11G)
🎛️ User controls included? (G7, G8, G9, G17)
📢 Change notification planned? (G18)
```

### 6.2 Post-Implementation Review

After implementing AI features:
```
🔍 RAI POST-IMPLEMENTATION REVIEW
Patterns Successfully Implemented: [List with ✅]
Patterns Needing Improvement: [List with 🎯]
User Education Provided: [List with 📚]
Complex Patterns Documented for Future: [List with 🚀]
```

## Rule 7: Continuous Monitoring and Improvement

### 7.1 Pattern Effectiveness Tracking
Monitor and report on:
- User interaction with RAI controls
- Feedback collection effectiveness (if implemented)
- User understanding of AI capabilities
- Misleading practice prevention success

### 7.2 Evolution and Updates
As HAX guidelines evolve:
- Update patterns based on new research
- Integrate user feedback on RAI implementations
- Refine misleading practice detection
- Enhance user education approaches

## Implementation Alerts

### Success Patterns
```
🎉 RAI EXCELLENCE ACHIEVED
Multiple guidelines implemented harmoniously
User-centric design with full transparency
Educational approach prioritizing user agency
Safety-first implementation with clear controls
```

### Warning Patterns  
```
⚠️ RAI ATTENTION NEEDED
Some guidelines implemented but gaps remain
User education opportunities missed
Consider enhanced transparency or control options
```

### Critical Patterns
```
🚨 RAI VIOLATION - IMMEDIATE ACTION REQUIRED
Misleading practices detected requiring resolution
User agency significantly limited
Transparency severely lacking
Safety mechanisms inadequate
```

---

**Reference**: Microsoft HAX Toolkit Complete Pattern Catalog (docs/responsible-ai-outline.md)
**Integration**: Works with privacy-security.mdc for comprehensive ethical AI
**Last Updated**: 2025-06-14
**Version**: 2.1
**Applies To**: All AI feature development and UI implementation
**Auto-Attachment**: Enabled for all code files, AI/ML components, and related infrastructure
